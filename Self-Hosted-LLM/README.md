# Self-Hosted Generic RAG System

Este projeto Ã© um sistema de **RAG (Retrieval-Augmented Generation)** hospedado localmente, projetado para transformar qualquer coleÃ§Ã£o de documentos de texto em uma Base de Conhecimento Inteligente.

Diferente de sistemas rÃ­gidos, este projeto se adapta Ã  **sua estrutura de pastas**. NÃ£o importa se vocÃª estÃ¡ organizando documentos jurÃ­dicos, tÃ©cnicos, receitas ou campanhas de RPG: a pasta define o contexto.

## ğŸš€ Principais Funcionalidades

-   **Modelos Locais (Ollama)**: Privacidade total. Seus documentos nunca saem da sua mÃ¡quina.
-   **CategorizaÃ§Ã£o DinÃ¢mica**: O sistema entende o contexto baseado no nome das suas pastas (Ex: `Marketing/CampanhaQ1.txt` -> Contexto: Marketing, Entidade: CampanhaQ1).
-   **Busca HÃ­brida Inteligente**: Combina **Vetores** (significado) com **BM25** (palavras-chave).
-   **Ãndices e Listas**: Prioriza arquivos de Ã­ndice (ex: `00_Resumo.txt`) quando vocÃª pede uma visÃ£o geral.
-   **Cross-Reference**: Entende quando vocÃª pergunta sobre "Projeto X" no contexto de "Financeiro" e cruza as informaÃ§Ãµes.

## ğŸ“‚ Como Organizar seus Documentos

A "inteligÃªncia" do sistema vem da sua organizaÃ§Ã£o. Use a pasta `documentos/` como raiz.

### Estrutura Recomendada

```text
documentos/
â”œâ”€â”€ [CATEGORIA 1] (Ex: Tecnologia)
â”‚   â”œâ”€â”€ [ENTIDADE A].txt (Ex: Python.txt)
â”‚   â”œâ”€â”€ [ENTIDADE B].txt (Ex: Docker.txt)
â”‚   â””â”€â”€ 00_INDICE_TECNOLOGIA.txt (Resumo geral desta pasta)
â”‚
â”œâ”€â”€ [CATEGORIA 2] (Ex: Recursos Humanos)
â”‚   â”œâ”€â”€ Politica_Ferias.txt
â”‚   â”œâ”€â”€ Onboarding.txt
â”‚   â””â”€â”€ ...
```

-   **NÃ­vel 1 (Pastas)**: Define a **Categoria Geral** (Contexto).
-   **Arquivos**: Cada arquivo Ã© tratado como uma **Entidade** ou TÃ³pico EspecÃ­fico.
-   **Ãndices**: Arquivos comeÃ§ando com `00_` ou contendo `INDICE` no nome sÃ£o tratados como prioritÃ¡rios para listagens.

## ğŸ› ï¸ InstalaÃ§Ã£o e Uso

### PrÃ©-requisitos
-   Python 3.12+
-   [Ollama](https://ollama.ai/) instalado e rodando.
-   Modelo LLM baixado (Recomendado: `gemma2:9b` ou `llama3`).

### 1. ConfiguraÃ§Ã£o
1.  Renomeie `.env.example` para `.env`.
2.  Edite `.env` e ajuste `LLM_MODEL` se necessÃ¡rio.

### 2. IngestÃ£o de Dados
Sempre que adicionar novos arquivos na pasta `documentos/`, rode:
```bash
py -3.12 ingest.py
```
Isso vai ler, categorizar e criar o "cÃ©rebro" vetorial do sistema.

### 3. Rodando o Chat
Para iniciar a API e comeÃ§ar a conversar:
```bash
py -3.12 api.py
```
Acesse a interface de documentaÃ§Ã£o (Swagger) em: `http://localhost:8000/docs`

## ğŸ§  Exemplos de Uso

-   **Pergunta EspecÃ­fica**: *"O que a politica de fÃ©rias diz sobre hora extra?"*
    -   O sistema detecta a entidade "Politica de Ferias" e busca exatamente lÃ¡.
-   **Pergunta Geral**: *"Quais tecnologias usamos?"*
    -   O sistema busca nos Ã­ndices da pasta Tecnologia.
-   **Cruzamento**: *"Como o Docker impacta o Onboarding?"*
    -   O sistema busca informaÃ§Ãµes tanto de Tecnologia/Docker quanto de RH/Onboarding.
