# RAG Test Suite

Este reposit√≥rio cont√©m uma implementa√ß√£o h√≠brida de sistemas RAG (Retrieval-Augmented Generation), integrando uma solu√ß√£o local (Self-Hosted) e uma solu√ß√£o em nuvem (Cloud Gemini), ambas acess√≠veis atrav√©s de uma interface de chat unificada (LibreChat).

## üèóÔ∏è Arquitetura

O sistema √© composto por tr√™s partes principais:

1.  **LibreChat (Docker)**: Interface de chat moderna que orquestra as conversas e se comunica com as APIs de RAG.
2.  **Cloud-Gemini-LLM (Docker)**: API RAG que utiliza o Google Gemini 2.5 Flash e ChromaDB. Roda dentro da rede Docker.
3.  **Self-Hosted-LLM (Local Host)**: API RAG que roda diretamente na m√°quina host, utilizando modelos locais (ex: Llama 3.1 com Ollama).

## üìã Pr√©-requisitos

- **Docker Desktop** instalado e rodando.
- **Python 3.12** instalado.
- **Chave de API do Google AI Studio** (para o Gemini).
- **Ollama** (para o Self-Hosted LLM) rodando localmente (opcional, mas necess√°rio para a parte local funcionar plenamente).

## ‚öôÔ∏è Configura√ß√£o

### 1. Cloud-Gemini-LLM
Configure a chave de API na pasta `Cloud-Gemini-LLM`:
1.  Entre na pasta: `cd Cloud-Gemini-LLM`
2.  Crie um arquivo `.env` com sua chave:
    ```env
    GOOGLE_API_KEY=sua_chave_aqui
    ```

### 2. Self-Hosted-LLM
Prepare o ambiente local:
1.  Entre na pasta: `cd Self-Hosted-LLM`
2.  Instale as depend√™ncias:
    ```bash
    pip install -r requirements.txt
    ```

### 3. LibreChat
A configura√ß√£o do LibreChat j√° est√° definida em `librechat.yaml` e `docker-compose.yml` para conectar aos dois servi√ßos.
- O servi√ßo `Cloud-Gemini-LLM` √© acessado via nome de container: `http://cloud-gemini-rag:8001`.
- O servi√ßo `Self-Hosted-LLM` √© acessado via gateway do Docker: `http://host.docker.internal:8000`.

## üöÄ Execu√ß√£o

Para rodar todo o sistema, voc√™ precisar√° de **dois terminais**.

### Terminal 1: API Local (Self-Hosted)
Inicie a API que roda fora do Docker:

```powershell
cd Self-Hosted-LLM
py -3.12 -m uvicorn api:app --host 0.0.0.0 --port 8000
```

### Terminal 2: Docker (LibreChat + Cloud API)
Inicie os servi√ßos Docker na raiz do projeto:

```powershell
docker-compose up
```

## üåê Acesso

Abra seu navegador e acesse o LibreChat:

**http://localhost:3080**

L√° voc√™ poder√° escolher entre os endpoints "Self Hosted RAG" e "Gemini Cloud RAG".

## üõ†Ô∏è Troubleshooting

- **Erro de Conex√£o com Self-Hosted**: Se o LibreChat n√£o conseguir conectar ao `Self-Hosted RAG`, verifique se o Docker consegue resolver `host.docker.internal`. No Windows com WSL2, isso geralmente funciona por padr√£o.
- **Banco Vetorial Vazio**: Se as respostas forem gen√©ricas, certifique-se de ter rodado os scripts de ingest√£o (`ingest.py`) dentro de cada pasta de projeto (`Cloud-Gemini-LLM` e `Self-Hosted-LLM`) para popular os bancos de dados vetoriais.
