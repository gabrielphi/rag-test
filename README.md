# ğŸ§  Local RAG Chatbot

Uma aplicaÃ§Ã£o de **RAG (Retrieval-Augmented Generation)** totalmente local, que permite conversar com seus documentos PDF e TXT usando **Ollama** e **LangChain**.

## ğŸš€ Funcionalidades

- **100% Local**: Nenhum dado sai da sua mÃ¡quina.
- **Suporte a PDFs e TXT**: IngestÃ£o de mÃºltiplos arquivos.
- **CitaÃ§Ãµes**: Indica exatamente qual documento e pÃ¡gina foi usado para a resposta.
- **Embeddings MultilÃ­ngues**: Configurado com `paraphrase-multilingual-MiniLM-L12-v2` para melhor performance em PortuguÃªs.

## ğŸ“‹ PrÃ©-requisitos

1. **Python 3.12+** instalado.
2. **[Ollama](https://ollama.com/)** instalado e rodando.
3. Modelo **Llama 3.2** (3B) baixado no Ollama:
   ```bash
   ollama pull llama3.2:3b
   ```

## ğŸ› ï¸ InstalaÃ§Ã£o

1. Clone ou baixe este repositÃ³rio.
2. Instale as dependÃªncias:
   ```bash
   pip install -r requirements.txt
   ```

## âš™ï¸ Como Usar

### 1. Preparar Documentos
Coloque seus arquivos `.pdf` e `.txt` dentro da pasta:
```
/documentos
```

### 2. Criar Banco Vetorial (IngestÃ£o)
Execute o script de ingestÃ£o sempre que adicionar novos arquivos. Ele processarÃ¡ os textos e salvarÃ¡ no banco de dados local (`vector_db`).
```bash
python ingest.py
```
*SaÃ­da esperada:*
```
âœ… [PDF] Carregado: 'Manual Beneficios 2024' (12 pÃ¡ginas)
ğŸ§  Gerando embeddings...
ğŸš€ Sucesso! Banco vetorial salvo em 'vector_db'.
```

### 3. Iniciar o Chat
Execute o aplicativo principal para conversar com seus dados.
```bash
python app.py
```

### 4. Interagindo
- Digite sua pergunta e pressione Enter.
- O sistema buscarÃ¡ os 3 trechos mais relevantes e gerarÃ¡ uma resposta.
- Digite `sair` para encerrar.

## ğŸ“‚ Estrutura do Projeto

- `app.py`: Script principal do chat (interface usuÃ¡rio).
- `ingest.py`: Script para processar documentos e criar o banco vetorial.
- `requirements.txt`: Lista de dependÃªncias Python.
- `documentos/`: Pasta onde vocÃª coloca seus arquivos (PDF/TXT).
- `vector_db/`: Pasta gerada automaticamente contendo o banco de dados vetorial (ChromaDB).

## âš ï¸ SoluÃ§Ã£o de Problemas comuns

**Erro: `vector_db` nÃ£o encontrado**
- Rode `python ingest.py` primeiro.

**Erro: `Dimension mismatch`**
- Certifique-se de que `app.py` e `ingest.py` usem o mesmo `EMBEDDING_MODEL_NAME`.
- Se mudou o modelo, delete a pasta `vector_db` e rode `ingest.py` novamente.

**Erro: Ollama connection refused**
- Verifique se o aplicativo do Ollama estÃ¡ aberto e rodando em background.
